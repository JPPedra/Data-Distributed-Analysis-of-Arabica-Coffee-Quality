---
title: "CS5811-Data Distributed Analysis-Data Analysis on Arabica Coffee Beans"
author: "Hawra Nawrozzadeh and Joao Pedro Azevedo"
date: "10/02/2022"
output: html_document
version: 1.0
editor_options: 
  chunk_output_type: inline
---

# 1. Introduction
This R Markdown report provides an data analysis of the dataset on the Arabica beans that was extracted from the Coffee Quality Institute. The aim of this report is to perform a supervised machine learning to answer the following research question: 
***"Given the attributes of this dataset, can we predict the overall coffee quality score?"*** 
The metadata on the Arabica coffee beans is as described as below:
---- 
| Attributes            | Description                                               |
| :----                 | :----                                                     |
| ID                    | ID of each coffee bean sample                             |   
| Country.of.Origin     | Country of Origin of Beans                                |
| Farm.Name             | Name of the Farm                                          |
| Lot.Number            | The lot number of each coffee sample                      |
| Mill                  | Organisation for grinding the coffee bean to cup?         |
| ICO.Number            | Information Commissioner's Office (ICO) for each company  |
| Company               | Company which made the coffee                             |
| Altitude              | Altitude of the farm                                      |
| altitude_low_meters   | Minimum altitude of the farm                              |
| altitude_high_meters  | Maximum altitude of the farm                              |
| altitude_mean_meters  | Altitude of the farm                                      |
| unit_of_measurement   | Unit of Measurement for the Altitude of the farm          |
| Region                | Region of each coffee sample                              |
| Producer              | Producer of each company                                  |
| Number.of.Bags        | Number of bags harvested                                  |
| Bag.Weight            | Weight of each harvested bag                              |
| In.Country.Partner    | Partner of the Company in the Country of Origin           |
| Harvest.Year          | The year it was harvest                                   |
| Grading.Date          | Date the Coffee was reviewed                              |
| Owner                 | Owner of the Company or the Company Name                  |
| Owner.1               | Owner of the Company or the Company Name                  |
| Variety               | Variety of Coffee                                         |
| Processing.Method     | Method by Which the Beans were Processed                  |

Attributes on the cupping scores Metadata:
| Attributes            | Description                                                 |
| :----                 | :----                                                       |
| Aroma                 | Reviewer's Score of Aroma on a 1-10 scale                   |
| Flavor                | Reviewer's Score of Flavor on a 1-10 scale                  |
| Aftertaste            | Reviewer's Score of Aftertaste on a 1-10 scale              |
| Acidity               | Reviewer's Score of Acidity on a 1-10 scale                 |
| Body                  | Reviewer's Score of Body on a 1-10 scale                    |
| Balance               | Reviewer's Score of Balance on a 1-10 scale                 |
| Uniformity            | Reviewer's Score of Uniformity on a 1-10 scale              |
| Clean.Cup             | Reviewer's Score of "Transparency of a cup" on a 1-10 scale |
| Sweetness             | Reviewer's Score of Sweetness on a 1-10 scale               |
| Cupper.Point          | Reviewer's Holistic Score of the cup on a 1-10 scale        |
| Total.Cup.Points      | Sum of the Reviewer's Scores                                |

Attributes on the green analysis Metadata:
| Attributes            | Description                                                                   |
| :----                 | :----                                                                         |
| Mositure              | Moisture percentage from Green Analysis                                       |
| Category.One.Defects  | Major defects in the beans                                                    |
| Quakers               | An unripe bean	that appears pale	when roasted with	a	cereal or bitter flavor |
| Color                 | Color of the Greens                                                           |
| Category.Two.Defects  | Minor defects in the beans                                                    |
| Species               | Arabica coffee bean species                                                   |

Attributes on the certification information Metadata:
| Attributes            | Description                                                                   |
| :----                 | :----                                                                         |
| Expiration            | Expiration of the certification of the bean                                   |
| Certification.Body    | Certification Body of each company                                            |
| Certification.Address | Certification Address of each company                                         |
| Certification.Contact | Certification Contact of each company                                         |
----

In order to achieve and perform machine learning, the first stage is to preform data cleaning and preparation in order to optimise the dataset and to ensure the quality of the dataset is accurate, consistent, and reliable. Exploratory Data Analysis will than be performed to explore and find patterns within the dataset that will provide further insights to approach and answer the research utilizing supervised learning technique accordingly. This report will also include importing results from high performance techniques (from Spark) in certain aspects of data cleaning and EDA.

# 2. Loading the Libraries

```{r}
# For data cleaning and preparation
library(dplyr)
library(tidyverse)
library(validate)
library(plyr)
# For Data visualisation
library(ggplot2)
library(magrittr)
library(graphics)
library(rgdal)
library(maptools)
library(Matrix)
library(broom.mixed)
library(readr)
library(caret)
library(mlbench)
library(ranger)
library(assertive)
library(forcats)
```

# 3. Data Cleaning and Preparation

## 3.1 Loading the data 

```{r}
coffee <- read.csv("ArabicaCoffeeBeans.csv")
```


## 3.2 Data Qaulity Check, Data Cleaning and Preparation 

Let's look into the structure of the data set
```{r}
str(coffee)
summary(coffee)
```

-From the 'summary()' and 'str()' function, it seems R has processed the dataset with  35 attributes categorical variables and the rest of the 9 attributes to be numerical continuous.
- However, this seems to be incorrect format because the in correct datatype.
  - For example, variables such as 'Acidity' and 'Aftertaste' contains numerical observations however, has been processed as character data types.
- Additionally, we can already identify errors such as missing data and possible outliers (from looking at the ranges from the summary function)

- Lets further look into the different levels by creating an object that converts the strings into a factor.
  - using 'stringAsFactor = T'
- By doing this, we can also see other details that we will help us to decide which attributes are redundant or irrelavent for our research question. 

```{r}
coffee_fac_lev <- read.csv("ArabicaCoffeeBeans.csv", stringsAsFactors = T)
str(coffee_fac_lev)
summary(coffee_fac_lev)
```

- There is alot of errors and redudant information
- can see the amount of missings informations, etc. 

Validate Package and Quality Rules
Through the validate Package we check if in the data set the variables are accurate and if there are any missing values.
The coffee.rules are useful to check the quality of data. We have created the data rules based on the 'structure' and on the 'summary' functions.

```{r}
#coffee.rules <- validator(
#check if data type is correct
#check.NBags.DataType = is.numeric(Number.of.Bags),
#check.Aroma.DataType = is.numeric(Aroma),
#check.Flavor.DataType = is.numeric(Flavor),
#check.Taste.DataType = is.numeric(Aftertaste),
#check.Acidity.DataType = is.numeric(Acidity),
#check.Body.DataType = is.numeric(Body),
#check.Balance.DataType = is.numeric(Balance),
#check.Uniformity.DataType = is.numeric(Uniformity),
#check.CleanCup.DataType = is.numeric(Clean.Cup),
#check.TotCupPoints.DataType = is.numeric(Total.Cups.Points),
#check.CupperPoints.DataType = is.numeric(Cupper.Points),
#check.Moisture.DataType = is.numeric(Moisture),
#check.CategoryOneDef.DataType = is.numeric(Category.One.Defects),
#check.ProcessMeth.DataType = is.factor(Processing.Method),
#check.Quakers.DataType = is.factor(Quakers),

#CheckWeight = is.element(Bag.Weight, ("kg")), #check unit of measure

#check spelling
#CheckProcessMeth = is.element(Processing.Method,
#c("Washed / Wet", "Natural/ Dry", "Pulped natural / honey", "Semi-washed / Semi-pulped", "Other")),
#CheckColor = is.element(Color,
#c("Green", "None" , "Bluish-Green", "Blue-Green")), #check spelling
#
#CheckNoBags = Number.of.Bags>0, #check no negatives
#CheckFlavor = Flavor>0, #check no negatives
#CheckAftertaste = Aftertaste>0, #check no negatives
#CheckAcidity = Acidity>0, #check no negatives
#CheckBody = Body>0, #check no negatives
#CheckBalance = Balance>0, #check no negatives
#CheckMoisture = Moisture>0, #check no negatives
#CheckQuakers = Quakers>=0, #check no negatives
#
#CheckMaxLowAltitute = altitude_low_meters>=1,
#CheckMinAltitute = altitude_low_meters <= 190164,
#CheckMaxHighAltitute = altitude_high_meters>=1,
#CheckMinHighAltitute = altitude_high_meters <= 190164,
#CheckMaxMeanAltitute = altitude_mean_meters>=1,
#CheckMinMeanAltitute = altitude_mean_meters <= 190164
#)
```
The 'quality.check' function used below will check if all items in the coffee.rules created, can pass or fail. Moreover, we can check how many missing values there are for each variable. If a rule do not pass, the error column will display 'True', otherwise it display 'False'
```{r}
#quality.check <- confront(coffee_new, coffee.rules) # To check the coffee quality rules
#summary (qual.check)
```

Through the plot we can visualize better the errors found in the quality check.
```{r}
#plot (quality.check)#to visualize the quality check of the coffee through a plot
```

- As a results, in order to answer our research, we will subset the dataset to contain the following variables: 
  - Country.of.Origin       
  - Number.of.Bags               
  - Bag.Weight                                   
  - Processing.Method                             
  - Aroma                                         
  - Flavor                                        
  - Aftertaste                                    
  - Acidity                                       
  - Body                                          
  - Balance                                       
  - Uniformity                                    
  - Clean.Cup                                     
  - Sweetness                                     
  - Cupper.Points                                 
  - Total.Cup.Points                              
  - Moisture                                      
  - Category.One.Defects                          
  - Quakers                                       
  - Category.Two.Defects  

## 3.3 Subsetting the Dataset

- Will now subset the dataset
```{r} 
# Lets get the column names
colnames(coffee)

# Are subsetting and removing the following columns mainly because all these variables had missing variables and would not help in answering our research question
coffee_new <- coffee %>%
  select(-c( ## removing data regarding the Farm 
            "Owner", "Farm.Name", "Lot.Number", "Mill", "ICO.Number",
            "Company","Region","Producer","In.Country.Partner","Harvest.Year","Owner.1","Variety", "Expiration",
            "Certification.Body","Certification.Address","Certification.Contact","unit_of_measurement",
            ## removing data regard the bean
            "Color", "Species", "Altitude", "altitude_low_meters", "altitude_high_meters", "altitude_mean_meters","Grading.Date"
            )
         )
# Let check the new changes
colnames(coffee_new)
str(coffee_new)
summary(coffee_new)
```
## 3.4 Data Type Conversion and Dealing with Missing Information
- Let's see if there are still any missing rows and if so, let remove them
```{r}
summary(coffee_new)
colSums(is.na(coffee_new))
colSums(coffee_new == "")

#https://stackoverflow.com/questions/42721788/filter-empty-rows-from-a-dataframe-with-r
coffee_new_1 <- coffee_new[Reduce(`&`, lapply(coffee_new, 
                                              function(x) !(x==""))),]

colSums(is.na(coffee_new_1))
colSums(coffee_new_1 == "")
```

Perform data type conversion 
- character to factors
- character that hold numbers to double numerical 
- excluding bag weight as the conversion would not work -> both string and "number" and the units are not the same
```{r}
#converting data type as factor
coffee_new_1$Processing.Method<-as.factor(coffee_new_1$Processing.Method)

#converting data type as double numerical
coffee_new_1$Number.of.Bags <- as.double(coffee_new_1$Number.of.Bags)
coffee_new_1$Quakers<-as.factor(coffee_new_1$Quakers)

coffee_new_1$Aroma<-as.double(coffee_new_1$Aroma)
coffee_new_1$Flavor<-as.double(coffee_new_1$Flavor)
coffee_new_1$Aftertaste<-as.double(coffee_new_1$Aftertaste)
coffee_new_1$Acidity<-as.double(coffee_new_1$Acidity)
coffee_new_1$Body<-as.double(coffee_new_1$Body)
coffee_new_1$Balance<-as.double(coffee_new_1$Balance)
coffee_new_1$Uniformity<-as.double(coffee_new_1$Uniformity)
coffee_new_1$Clean.Cup<-as.double(coffee_new_1$Clean.Cup)
coffee_new_1$Total.Cup.Points<-as.double(coffee_new_1$Total.Cup.Points)
coffee_new_1$Cupper.Points<-as.double(coffee_new_1$Cupper.Points)
coffee_new_1$Moisture<-as.double(coffee_new_1$Moisture)
coffee_new_1$Category.One.Defects<-as.double(coffee_new_1$Category.One.Defects) 
#checking the structure of the data set with new data types
str(coffee_new_1)
```

- Then apply NA imputation to all numerical variables
```{r}
# impute missing values by replacement with the mean value
  # using mutate_if function and if else condition to find any NAs in any numerical columns and replace it with their according median
coffee_new_1 <- coffee_new_1 %>% 
  mutate_if(is.numeric, function(x) ifelse(is.na(x), median(x, na.rm = T), x))
colSums(is.na(coffee_new_1))
```

Moreover, it is also crucial to investigate whether the current dataset has any duplicate values - using table and duplicate functions.

```{r}
table(duplicated(coffee_new_1))
```

The output returns FALSE for 1154 rows, meaning that the current dataset has no duplicated values.

Moreover, 
-dealing with Bag Weight problem
  - all string 
  - Majority is kg put there are some in lbs
  - Created a function to fix this so that all the values are converted to numeric and all have the same unit
  
```{r}
#Will now load the results from the function that was performed in Pyspark (Hawra's HPCI technqiue)
coffee_new_1 <- read.csv("Data/ArabicaCoffeeBeansNew-UnitConversionWithString.csv")

```

```{r}
# have to change the fake number to NA before doing NA imputation to Bag Weight , will use the naniar function
table(coffee_new_1$Bag.Weight)
library(naniar)
#exp<- coffee_new_1
coffee_new_1 <- coffee_new_1 %>% 
  replace_with_na(replace = list(Bag.Weight = 99999))
table(coffee_new_1$Bag.Weight)
colSums(is.na(coffee_new_1))
```

```{r}
# Then perform NA imputation to Bag weight

median_Bag_weight <- median(coffee_new_1$Bag.Weight, na.rm = T)
coffee_new_1[is.na(coffee_new_1$Bag.Weight), 10.000] = median_Bag_weight

# Then drop any other NA from the character variables

coffee_new_1 <- na.omit(coffee_new_1)
```


## 3.5 Identifying and Dealing with Outliers - Data Preparation and Cleaning 

```{r}
str(coffee_new_1)
```



# 1- Country.of.Origin 

```{r}

table(coffee_new_1$Country.of.Origin)


coffee_new_1["Country.of.Origin"][coffee_new_1["Country.of.Origin"] == "Cote d?Ivoire"] = "Cote d'Ivoire"


coffee_new_1["Country.of.Origin"][coffee_new_1["Country.of.Origin"] == "Tanzania, United Republic Of"] = "United Republic of Tanzania"


coffee_new_1["Country.of.Origin"][coffee_new_1["Country.of.Origin"] == "United States (Hawaii)"] = "Hawaii"
```



# 2- Number.of.Bags 

```{r}
coffee_new_1$Number.of.Bags <- as.numeric(coffee_new_1$Number.of.Bags)

ggplot(coffee_new_1, aes(Number.of.Bags)) + geom_boxplot(color="Blue",fill="#69b3a2") + theme_minimal() + ggtitle("Number.of.Bags Boxplot")
```


```{r}
bags_boxplot <- boxplot(coffee_new_1$Number.of.Bags, plot = F)

# minimum function will get this number as the minimum outlier possible
bags_threshold <- min(bags_boxplot$out)

bags_threshold # returns 1062, which is the outlier identified in the summary function
```


```{r}
# function to identify which country has 1062 number of bags
subset(coffee_new_1, Number.of.Bags == 1062.0) # output returns the country Brazil 

# function to understand if it is the norm for Brazil to have 1062.0 number of bags
subset(coffee_new_1, Country.of.Origin == "Brazil")
```


# 3 - Quakers

```{r}
count(coffee_new_1, 'Quakers')

coffee_new_1[is.na(coffee_new_1$Quakers) , ] = 0

ggplot(coffee_new_1, aes(Quakers)) + geom_boxplot(color="black",fill="gold") + theme_minimal() + ggtitle("Quakers in the coffee quality")
```


# 4 - Processing.Method

```{r}
count(coffee_new_1, 'Processing.Method')

coffee_new_1[is.na(coffee_new_1$Processing.Method) , ] <- "Other"

ggplot(coffee_new_1, aes(Processing.Method)) + geom_bar(fill="steelblue", colour = "darkgreen", size = 1.2) + coord_flip() 
```

# 5 -  Total.Cup.Points - score coffee on a standardized scale, from 0 to 100.

```{r}
aggregate(coffee_new_1$Total.Cup.Points, list(coffee_new_1$Country.of.Origin), FUN=mean)

ggplot(coffee_new_1, aes(Total.Cup.Points)) + geom_boxplot(color="black",fill="lightblue",linetype="dashed") + theme_minimal() + ggtitle("Quakers in the coffee quality")

```

```{r}
bags_boxplot1 <- boxplot(coffee_new_1$Total.Cup.Points, plot = F)


bags_threshold1 <- min(bags_boxplot1$out)
bags_threshold2 <- max(bags_boxplot1$out)

bags_threshold1 
bags_threshold2 

```

# 6 - Aroma, Flavor, Aftertaste, Acidity, Body, Balance, Uniformity, Clean.Cup, Sweetness

```{r}
coffee_new_1$Sweetness <- as.numeric(coffee_new_1$Sweetness)

coffee_new_1$Cupper.Points <- as.numeric(coffee_new_1$Cupper.Points)


boxplot(coffee_new_1$Aroma,coffee_new_1$Flavor,coffee_new_1$Aftertaste,main = "Boxplot 1 for comparision of three numerical variables", names = c("Aroma", "Flavor", "Aftertaste"), col = c("orange","red"), border = "brown", horizontal = TRUE, notch = TRUE)

boxplot(coffee_new_1$Acidity,coffee_new_1$Body,coffee_new_1$Balance,main = "Boxplot 2 for comparision of three numerical variables", names = c("Acidity", "Body", "Balance"), col = c("blue","black"), border = "brown", horizontal = TRUE, notch = TRUE)

boxplot(coffee_new_1$Uniformity,coffee_new_1$Clean.Cup,coffee_new_1$Sweetness,main = "Boxplot 3 for comparision of three numerical variables", names = c("Uniformity", "Clean.Cup", "Sweetness"), col = c("red","yellow"), border = "brown", horizontal = TRUE, notch = TRUE)
```


```{r}
Aroma_boxplot <- boxplot(coffee_new_1$Aroma, plot = F)
Aroma_threshold <- min(Aroma_boxplot$out)
Aroma_threshold # value of the possible outlier for aroma is 5.08

Acidity_boxplot <- boxplot(coffee_new_1$Acidity, plot = F)
Acidity_threshold <- min(Acidity_boxplot$out)
Acidity_threshold # value of the possible outlier for aroma is 5.25

Body_boxplot <- boxplot(coffee_new_1$Body, plot = F)
Body_threshold <- min(Body_boxplot$out)
Body_threshold # value of the possible outlier for aroma is 6.33

Clean.Cup_boxplot <- boxplot(coffee_new_1$Clean.Cup, plot = F)
Clean.Cup_boxplot_threshold <- min(Clean.Cup_boxplot$out)
Clean.Cup_boxplot_threshold # value of the possible outlier for aroma is 6.33

subset(coffee_new_1, Aroma == 5.08)
subset(coffee_new_1, Acidity == 5.25)
subset(coffee_new_1, Body == 6.33)
subset(coffee_new_1, Clean.Cup == 0)
```


# 7 - Cupper.Points and Clean.Cup

```{r}

boxplot(coffee_new_1$Cupper.Points,coffee_new_1$Clean.Cup,main = "Boxplot of Cupper Points and Clean Cup", names = c("Cupper.Points", "Clean.Cup"), col = c("orange","red"), border = "brown", horizontal = TRUE, notch = TRUE, size = 30)

count(coffee_new_1, 'Cupper.Points')
count(coffee_new_1, 'Clean.Cup')
```


# 8 - Moisture

```{r}
ggplot(coffee_new_1, aes(Moisture)) + geom_boxplot(color="purple",fill="blue",linetype="dashed") + theme_minimal() + ggtitle("Moisture of the Coffee Beans")

count(coffee_new_1, 'Moisture')
```

# 8 - Category.One.Defects and Category.Two.Defects

```{r}
count(coffee_new_1, 'Category.One.Defects')
count(coffee_new_1, 'Category.Two.Defects')

boxplot(coffee_new_1$Category.One.Defects,coffee_new_1$Category.Two.Defects,main = "Boxplot of Cupper Points and Clean Cup", names = c("Category.One.Defects", "Category.Two.Defects"), col = c("red","gold"), border = "brown", horizontal = TRUE, notch = TRUE)

``` 


```{r}
category_boxplot <- boxplot(coffee_new_1$Category.Two.Defects, plot = F)

category_threshold <- min(category_boxplot$out)


dataset_clean <- coffee_new_1[coffee_new_1$Category.Two.Defects< min(category_boxplot$out), ]
dataset_clean


ggplot(dataset_clean, aes(Category.One.Defects,Category.Two.Defects)) + geom_boxplot(color="black",fill="gold") + theme_minimal() + ggtitle("Category Defects")
```


# 4.EDA

```{r}
summary(coffee_new_1)
```

# 4.1 - Explore each variable individually
```{r}

ggplot(coffee_new_1, aes(x=Total.Cup.Points)) + geom_histogram(aes(y=..density..), binwidth=1, colour="black", fill="goldenrod2") +
  # Overlay with transparent (use the alpha parameter) blue density plot  
  geom_density(alpha=.2, fill="black") +   
  xlab("Coffee Cup Score") +
  ggtitle("Histogram and density plot of Cup Score")
```


```{r}
library(ggplot2)
library(ggpubr)
theme_set(theme_pubr())

plot1<- ggplot(coffee_new_1, aes(Category.One.Defects)) + geom_histogram(aes(y=..density..), binwidth=2, colour="black", fill="goldenrod2") + geom_density(alpha=.2, fill="blue")

plot2<- ggplot(coffee_new_1, aes(Category.Two.Defects)) + geom_histogram(aes(y=..density..), binwidth=3, colour="black", fill="goldenrod2") + geom_density(alpha=.2, fill="darkblue")

plot3<- ggplot(coffee_new_1, aes(Quakers)) + geom_histogram(aes(y=..density..), binwidth=0.7, colour="black", fill="goldenrod2") + ggtitle("Coffee Quakers") + geom_density(alpha=.2, fill="red")

# function that combines the 3 plots for a easier visualization 
plots <- ggarrange(plot1, plot2, plot3,
                    labels = c("Defects I", "Defects II","Quakers"),
                    ncol = 3, nrow = 1)
plots
```

```{r}
qplot(Category.One.Defects,Category.Two.Defects, data = coffee_new_1, colour = Quakers)
```


```{r}

par(mfrow=c(1,4)) # Part I

hist(coffee_new_1$Aroma, main="Histogram of coffee Aroma",xlab="Coffee´s Aroma", ylab="", col = " light blue")

hist(coffee_new_1$Flavor, main="Histogram of coffee Flavor",xlab="Coffee´s Flavor", ylab="", col = " dark red")

hist(coffee_new_1$Aftertaste, main="Histogram of coffee Aftertaste",xlab="Coffee´s Aftertaste", ylab="", col = " light blue")

hist(coffee_new_1$Acidity, main="Histogram of coffee Acidity",xlab="Coffee´s Acidity", ylab="", col = " dark red")

par(mfrow=c(1,4)) # Part II

hist(coffee_new_1$Body, main="Histogram of coffee Body",xlab= "Coffee´s Body", ylab="", col = " light blue")

hist(coffee_new_1$Balance, main="Histogram of coffee Balance",xlab="Coffee´s Balance", ylab="", col = " dark red")

hist(coffee_new_1$Sweetness, main="Histogram of coffee Sweetness",xlab="Coffee´s Sweetness", ylab="", col = " light blue")

hist(coffee_new_1$Clean.Cup, main="Histogram of coffee Clean.Cup",xlab="Coffee´s Clean.Cup", ylab="", col = " dark red")
```


```{r}
ggplot(coffee_new_1, aes(x=Sweetness)) + geom_histogram(aes(y=..density..), 
                 binwidth=0.9, 
                 colour="black", 
                 fill="goldenrod2") +
  
  # Overlay with transparent (use the alpha parameter) blue density plot  
  geom_density(alpha=.2, fill="black") +   
  xlab("Coffee Sweetness") +
  ggtitle("Histogram and density plot of Coffee Sweetness")

count(coffee_new_1, 'Sweetness')
```


```{r}
ggplot(coffee_new_1, aes(x=Clean.Cup)) + geom_histogram(aes(y=..density..), 
                 binwidth=0.9, 
                 colour="blue", 
                 fill="goldenrod2") +
  
  # Overlay with transparent (use the alpha parameter) blue density plot  
  geom_density(alpha=.2, fill="blue") +   
  xlab("Coffee Clean.Cup") +
  ggtitle("Histogram and density plot of Coffee Clean.Cup")

count(coffee_new_1, 'Clean.Cup')
```


```{r}
# country of origin
sample_info_1 <- coffee_new_1%>%
  count(Country.of.Origin)%>%
  arrange(desc(n))%>%
  ggplot(aes(x = n, y = reorder(Country.of.Origin, n))) + 
  geom_bar(stat = "identity", fill = "#0072B2") + 
  labs(y = "Country of Origin", x = "Number of Arabica Coffee Beans Produced") + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
                                          panel.background = element_blank(), axis.line = element_line(colour = "pink"))

# processing method
sample_info_2 <- coffee_new_1%>%
  count(Processing.Method)%>%
  arrange(desc(n))%>%
  ggplot(aes(x = n, y = reorder(Processing.Method, n))) + 
  geom_bar(stat = "identity", fill = "#0072B2") + 
  labs(y = "Processing Methods", x = "Number of Arabica Coffee Beans") + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
                                          panel.background = element_blank(), axis.line = element_line(colour = "pink"))
# Number.of.bag
sample_info_3 <- ggplot(coffee_new_1, aes(x=Number.of.Bags)) + 
               geom_histogram(breaks=seq(0,100,by=10), fill="#69b3a2", color="#e9ecef", alpha=0.9)
             
sample_info_4 <- ggplot(coffee_new_1, aes(x=Bag.Weight)) + 
  geom_histogram(breaks=seq(0,100,by=10), fill="#69b3a2", color="#e9ecef", alpha=0.9)

library(gridExtra)
grid.arrange(sample_info_1, sample_info_2, sample_info_3, sample_info_4)
```

# 4.2 - analyse the continuous variables graphically against the Total.Cup.Points variable


```{r}
colnames(coffee_new_1)

# Reorder following the value of another column:
coffee_new_1 %>%
  mutate(Country.of.Origin = fct_reorder(Country.of.Origin, Total.Cup.Points)) %>%
  ggplot( aes(x=Country.of.Origin, y=Total.Cup.Points)) +
    geom_bar(stat="identity", fill="#f68060", alpha=.6, width=.4) +
    coord_flip() +
    xlab("") +
    theme_bw()
```


```{r}
library(tidyverse)
coffee_new_1%>%
  filter(Country.of.Origin %in% c(coffee_new_1%>%
                                    count(Country.of.Origin)%>%
                                    filter(n >25)%>%
                                    pull(Country.of.Origin)))%>%
  filter(Processing.Method %in% c('Washed / Wet', 'Natural / Dry'))%>%
  count(Country.of.Origin, Processing.Method)%>%
  mutate(country = factor(Country.of.Origin, levels = c("Mexico", "Guatemala", "Colombia", "Brazil", 
                                                        "Taiwan", "Hawaii", "Honduras", "Costa Rica")))%>%
  ggplot(aes(x = country, y = n, fill = reorder(Processing.Method,-n))) + geom_col() + 
  labs(x = 'Number of Coffee', 
       y = 'Country', fill = 'Process Method') + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
                                                       panel.background = element_blank(), axis.line = element_line(colour = "black")) + 
  scale_fill_manual(values=c("azure3","#0072B2"))
```


```{r}
coffee_new_1 %>%
  mutate(Processing.Method = fct_reorder(Processing.Method, Total.Cup.Points, .fun='median')) %>%
  ggplot( aes(x=reorder(Processing.Method, Total.Cup.Points), y=Total.Cup.Points, fill=Processing.Method)) + 
    geom_boxplot() +
    xlab("Processing.Method") +
    theme(legend.position="none") +
    xlab("")
```


```{r}
# The plot below shos too much information - it is not necessary to plot the data like this.
#plot(coffee_new_1, aes(Category.One.Defects, Total.Cup.Points))
par(mfrow=c(1,3)) # Part II
attach(coffee_new_1)
plot(Total.Cup.Points, Category.One.Defects, main="Defects type I vs Coffee Score", 
   xlab="Total.Cup.Points", ylab="Category.One.Defects", pch=19, col = "dark red")

plot(Total.Cup.Points, Category.Two.Defects, main="Defects type II vs Coffee Score", 
   xlab="Total.Cup.Points", ylab="Category.Two.Defects", pch=19, col = "dark blue")

plot(Quakers, Quakers, Total.Cup.Points="Quakers vs Coffee Score", 
   xlab="Quakers", ylab="Total.Cup.Points", pch=19, col = "dark red")
```



```{r}
ggplot(coffee_new_1, aes(Moisture,Total.Cup.Points)) + geom_point(col = "dark red") + ggtitle("Moisture vs Total.Cup.Poins")
```


```{r}
qplot(Aroma, Flavor,  data = coffee_new_1, colour = Total.Cup.Points)
qplot(Aftertaste, Acidity, data = coffee_new_1, colour = Total.Cup.Points)
qplot(Acidity, Body, data = coffee_new_1, colour = Total.Cup.Points)

qplot(Balance,Uniformity, data = coffee_new_1, colour = Total.Cup.Points)
qplot(Clean.Cup,Uniformity, data = coffee_new_1, colour = Total.Cup.Points)
qplot(Cupper.Points, Clean.Cup, data = coffee_new_1, colour = Total.Cup.Points)
qplot(Balance,Uniformity, data = coffee_new_1, colour = Total.Cup.Points)
```


# HAWRA PART GUYS FOR HER TECHNIQUE and part of EDA AS WELL - make your own comments dont forget

Scatter plot matrix and a heatmap are two very powerful way of showing the correlation between all continuous variables. The Pearson's correlation coefficient, `r`, will be extracted and implemented. 

Before we create these plots, we will first rename some of the columns to improve the visualisations and for better readability. This will be into a new variable called `coffee_new_num` as the correlations can be only performed on numerical variables.
```{r}
str(coffee_new_1)
coffee_new_num <- coffee_new_1 %>%
  rename(Num.of.Bags = Number.of.Bags,
         Quality.Score = Total.Cup.Points,
         Cat.1.Defect = Category.One.Defects,
         Cat.2.Defect = Category.Two.Defects)
str(coffee_new_num)
``` 

Let's first plot the scatter plot matrix utilising the GGally package.
```{r}
library(GGally)
str(coffee_new_1)
#plot(coffee_num_new)
ggpairs(coffee_new_num[ ,-c(1,4)], title = "Scatterplot Matrix of the Numerical Features")
```

This plot provides alot of information. It shows the scatter plot and the r correlation value between all of the continuous variables and shows the density plot of each variable. From the scatter plot, there is many linear relationship with the target variable such as **Aroma** and **Flavour**. However, there are some variables such as **Bag.Weight** and **Uniformity** that show non-linearity with the target variable.

correlation test
```{r}
cor.test(coffee_new_1$Number.of.Bags, coffee_new_1$Total.Cup.Points) ## No correlations --> correlation is not significant
cor.test(coffee_new_1$Bag.Weight, coffee_new_1$Total.Cup.Points) ## No correlations --> correlation is not significant
cor.test(coffee_new_1$Aroma, coffee_new_1$Total.Cup.Points) ## correlation is significant 
cor.test(coffee_new_1$Flavor, coffee_new_1$Total.Cup.Points) ## correlation is significant 
cor.test(coffee_new_1$Aftertaste, coffee_new_1$Total.Cup.Points) ## correlation is significant 
cor.test(coffee_new_1$Acidity, coffee_new_1$Total.Cup.Points) ## correlation is significant 
cor.test(coffee_new_1$Body, coffee_new_1$Total.Cup.Points) ## correlation is significant 
cor.test(coffee_new_1$Uniformity, coffee_new_1$Total.Cup.Points) ## correlation is significant 
cor.test(coffee_new_1$Clean.Cup, coffee_new_1$Total.Cup.Points) ## correlation is significant 
cor.test(coffee_new_1$Sweetness, coffee_new_1$Total.Cup.Points) ## correlation is significant 
cor.test(coffee_new_1$Moisture, coffee_new_1$Total.Cup.Points) ## correlation is significant 
cor.test(coffee_new_1$Category.One.Defects, coffee_new_1$Total.Cup.Points) ## correlation is significant 
cor.test(coffee_new_1$Quakers, coffee_new_1$Total.Cup.Points) ## correlation is not significant
cor.test(coffee_new_1$Category.Two.Defects, coffee_new_1$Total.Cup.Points) ## correlation is significant 
```

All numerical variables show significant correlations expect for Number.of.bags, Bag.Weights, and Quakers

## PCA
Principle Component Analysis (PCA) is an useful feature extraction that involves reducing the number of dimension and removing background noises. This is useful technique to improve variation within the dataset and improve the predicitve modelling.

PCA is performed on all independent variables (expect for the country of origin due their high level of imbalance). Therefore, will encode the processing method using the command below:
```{r}
table(coffee_new_1$Processing.Method)

coffee_new_1$Processing.Method.Num <- coffee_new_1$Processing.Method

coffee_new_1$Processing.Method.Num <- as.character(coffee_new_1$Processing.Method.Num)
coffee_new_1["Processing.Method.Num"][coffee_new_1["Processing.Method.Num"] == "Natural / Dry"] <- "1"
coffee_new_1["Processing.Method.Num"][coffee_new_1["Processing.Method.Num"] == "Pulped natural / honey"] <- "2"
coffee_new_1["Processing.Method.Num"][coffee_new_1["Processing.Method.Num"] == "Semi-washed / Semi-pulped"] <- "3"
coffee_new_1["Processing.Method.Num"][coffee_new_1["Processing.Method.Num"] == "Washed / Wet"] <- "4"
coffee_new_1["Processing.Method.Num"][coffee_new_1["Processing.Method.Num"] == "Other"] <- "5"
coffee_new_1$Processing.Method.Num <- as.numeric(coffee_new_1$Processing.Method.Num)
```

PCA can be performed during the `prcomp()` function. This function involves transforming and scaling the dataset. By default, the z-score transformation is used, however, due the nature of the Arabica Coffee Dataset, using Min-Max Transformation is more appropriate. This is due to that fact most of dataset is range of scores and using the z-score would completely change the real value and would result misleading results.
```{r}
# create min and max values for the transformation
maxs <- apply(coffee_new_1[,c(-1,-4, -15, -20)], 2, max) 
mins <- apply(coffee_new_1[,c(-1,-4, -15, -20)], 2, min)

# will apply the min and max transformation for the PCA
# Need to exclude the target and the country.of.origin and Processing.Method (will the numerical version of Processing.Method - Processing.Method.Num)
coffee_pca <- prcomp(coffee_new_1[ ,-c(1,4,15, 20)], center = mins, scale = maxs - mins)
coffee_pca
summary(coffee_pca)
```

will plot the secree plot of the cumulative PEV against the PCs to see if there are any PCs are showing 80% variance.
```{r}
plot(coffee_pca)

opar <- par(no.readonly = TRUE)
plot(
  cumsum(coffee_pca$sdev^2/
           sum(coffee_pca$sdev^2)),
  ylim = c(0,1),
  xlab = 'PC',
  ylab = 'cumulative PEV',
  pch = 20,
  col = 'orange'
)
abline(h = 0.8, col = 'red', lty = 'dashed')
par(opar)
```

There is no significant PCs. Therefore, will use the orginal dataset for when performing the predicitve modelling.

From the correlations analysis, all the numerical independent variables will be used for the predictive modelling, expect for Number.of.bags, Bag.Weights, and Quakers.
Country.of.Origin will also not be used due their high level of imbalance.
As the Processing.Method have been encoded to a numerical data attribute, we can test and see if this variables has significant correlations to be used for the predicitve modelling
```{r}
cor.test(coffee_new_1$Processing.Method.Num, coffee_new_1$Total.Cup.Points)
```
There is no correlations between the Processing.Methods and the target variable, therefore, will not be used for the predictive modelling.

